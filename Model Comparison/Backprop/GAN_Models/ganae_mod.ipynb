{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the image shape  (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Adjust sys.argv to remove unwanted Jupyter arguments\n",
    "sys.argv = sys.argv[:1]  # Keep only the script name, remove Jupyter's arguments\n",
    "\n",
    "# Now proceed with argparse as usual\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=200, help=\"size of the batches\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of CPU threads for data loading\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=2000, help=\"interval between image sampling\")\n",
    "\n",
    "# Parse the arguments\n",
    "opt = parser.parse_args()\n",
    "\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "print(\"this is the image shape \", img_shape)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Loading Classes and Functions\n",
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, dataX, dataY=None):\n",
    "        self.dataX = np.load(dataX)\n",
    "        self.dataY = np.load(dataY) if dataY is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataX)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.dataX[idx], dtype=torch.float32)\n",
    "        label = (\n",
    "            torch.tensor(self.dataY[idx], dtype=torch.long)\n",
    "            if self.dataY is not None\n",
    "            else None\n",
    "        )\n",
    "        return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "dataX = \"../../../data/mnist/trainX.npy\"\n",
    "dataY = \"../../../data/mnist/trainY.npy\"\n",
    "devX = \"../../../data/mnist/validX.npy\"\n",
    "devY = \"../../../data/mnist/validY.npy\"\n",
    "testX = \"../../../data/mnist/testX.npy\"\n",
    "testY = \"../../../data/mnist/testY.npy\"\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset = NumpyDataset(dataX, dataY)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "dev_dataset = NumpyDataset(devX, devY)\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=200, shuffle=False)\n",
    "\n",
    "test_dataset = NumpyDataset(testX, testY)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=200, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mu_layer = nn.Linear(hidden_dims[1], latent_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dims[1], latent_dim)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in [*self.model, self.mu_layer, self.logvar_layer]:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h = self.model(x)\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, input_dim, hidden_dims):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[1], hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[0], input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x_recon = self.model(z)\n",
    "        return x_recon.view(-1, 1, 28, 28)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dims):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "class GANAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, latent_dim, l2_lambda=1e-3):\n",
    "        super(GANAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dims, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, input_dim, hidden_dims)\n",
    "        self.discriminator = Discriminator(latent_dim, hidden_dims)\n",
    "        self.l2_lambda = l2_lambda\n",
    "\n",
    "    def compute_l2_penalty(self):\n",
    "        l2_penalty = 0\n",
    "        for param in self.decoder.parameters():\n",
    "            if param.requires_grad:\n",
    "                l2_penalty += torch.sum(param**2)\n",
    "        return self.l2_lambda * l2_penalty\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        real_or_fake = self.discriminator(z)\n",
    "        return x_recon, real_or_fake, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss Functions ---\n",
    "def bce_loss(pred, target):\n",
    "    return F.binary_cross_entropy(pred, target,reduction=\"sum\")\n",
    "\n",
    "def gan_ae_loss(recon_x, x, real_or_fake, real_label=1, fake_label=0):\n",
    "    # Reconstruction loss\n",
    "    recon_loss =bce_loss(recon_x, x)\n",
    "\n",
    "    # Discriminator loss (binary cross entropy)\n",
    "    d_loss_real = bce_loss(real_or_fake, torch.full_like(real_or_fake, real_label))\n",
    "    d_loss_fake = bce_loss(real_or_fake, torch.full_like(real_or_fake, fake_label))\n",
    "\n",
    "    return recon_loss + d_loss_real + d_loss_fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "    Reconstruction Loss: 235.3823\n",
      "    KL Loss: 5.2138\n",
      "Epoch [2/50]\n",
      "    Reconstruction Loss: 168.9358\n",
      "    KL Loss: 9.4458\n",
      "Epoch [3/50]\n",
      "    Reconstruction Loss: 144.4751\n",
      "    KL Loss: 14.6902\n",
      "Epoch [4/50]\n",
      "    Reconstruction Loss: 133.1287\n",
      "    KL Loss: 17.3896\n",
      "Epoch [5/50]\n",
      "    Reconstruction Loss: 126.0369\n",
      "    KL Loss: 18.9535\n",
      "Epoch [6/50]\n",
      "    Reconstruction Loss: 120.3281\n",
      "    KL Loss: 20.1664\n",
      "Epoch [7/50]\n",
      "    Reconstruction Loss: 115.7630\n",
      "    KL Loss: 20.8037\n",
      "Epoch [8/50]\n",
      "    Reconstruction Loss: 111.7727\n",
      "    KL Loss: 21.3002\n",
      "Epoch [9/50]\n",
      "    Reconstruction Loss: 108.1102\n",
      "    KL Loss: 21.6270\n",
      "Epoch [10/50]\n",
      "    Reconstruction Loss: 104.7660\n",
      "    KL Loss: 21.8693\n",
      "Epoch [11/50]\n",
      "    Reconstruction Loss: 101.9605\n",
      "    KL Loss: 21.9848\n",
      "Epoch [12/50]\n",
      "    Reconstruction Loss: 99.4461\n",
      "    KL Loss: 22.0662\n",
      "Epoch [13/50]\n",
      "    Reconstruction Loss: 97.3891\n",
      "    KL Loss: 22.1528\n",
      "Epoch [14/50]\n",
      "    Reconstruction Loss: 95.5962\n",
      "    KL Loss: 22.2436\n",
      "Epoch [15/50]\n",
      "    Reconstruction Loss: 94.0786\n",
      "    KL Loss: 22.3053\n",
      "Epoch [16/50]\n",
      "    Reconstruction Loss: 92.8111\n",
      "    KL Loss: 22.4028\n",
      "Epoch [17/50]\n",
      "    Reconstruction Loss: 91.6522\n",
      "    KL Loss: 22.4978\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "# Initialize model with proper parameters\n",
    "input_dim = 784  # 28x28 for MNIST\n",
    "hidden_dims = [512, 256]  # Example dimensions\n",
    "latent_dim = 100  # Example latent dimension\n",
    "ganae = GANAE(input_dim=input_dim, hidden_dims=hidden_dims, latent_dim=latent_dim)\n",
    "\n",
    "# Separate optimizers for generator (encoder+decoder) and discriminator\n",
    "gen_optimizer = torch.optim.Adam(list(ganae.encoder.parameters()) + \n",
    "                               list(ganae.decoder.parameters()), lr=0.0002)\n",
    "disc_optimizer = torch.optim.Adam(ganae.discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss functions\n",
    "reconstruction_loss = nn.BCELoss(reduction='sum')\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "def compute_loss(x_recon, x, real_or_fake, mu, logvar):\n",
    "    # Reconstruction loss\n",
    "    recon_loss = reconstruction_loss(x_recon, x)\n",
    "    \n",
    "    # KL divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Adversarial loss\n",
    "    real_labels = torch.ones(real_or_fake.size()).to(x.device)\n",
    "    fake_labels = torch.zeros(real_or_fake.size()).to(x.device)\n",
    "    \n",
    "    # Generator tries to fool discriminator\n",
    "    gen_loss = adversarial_loss(real_or_fake, real_labels)\n",
    "    \n",
    "    # Discriminator loss\n",
    "    disc_loss = adversarial_loss(real_or_fake, fake_labels)\n",
    "    \n",
    "    return recon_loss, kl_loss, gen_loss, disc_loss\n",
    "# --- Training Loop ---\n",
    "# Initialize model with proper parameters\n",
    "input_dim = 784  # 28x28 for MNIST\n",
    "hidden_dims = [512, 256]  # Example dimensions\n",
    "latent_dim = 100  # Example latent dimension\n",
    "ganae = GANAE(input_dim=input_dim, hidden_dims=hidden_dims, latent_dim=latent_dim)\n",
    "\n",
    "# Separate optimizers for generator (encoder+decoder) and discriminator\n",
    "gen_optimizer = torch.optim.Adam(list(ganae.encoder.parameters()) + \n",
    "                               list(ganae.decoder.parameters()), lr=0.0002)\n",
    "disc_optimizer = torch.optim.Adam(ganae.discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "# Loss functions\n",
    "reconstruction_loss = nn.BCELoss(reduction='sum')\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "def compute_loss(x_recon, x, real_or_fake, mu, logvar):\n",
    "    # Flatten the input and reconstruction for BCE loss\n",
    "    x_recon_flat = x_recon.view(-1, input_dim)\n",
    "    x_flat = x.view(-1, input_dim)\n",
    "    \n",
    "    # Reconstruction loss\n",
    "    recon_loss = reconstruction_loss(x_recon_flat, x_flat)\n",
    "    \n",
    "    # KL divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Adversarial loss\n",
    "    real_labels = torch.ones(real_or_fake.size()).to(x.device)\n",
    "    fake_labels = torch.zeros(real_or_fake.size()).to(x.device)\n",
    "    \n",
    "    # Generator tries to fool discriminator\n",
    "    gen_loss = adversarial_loss(real_or_fake, real_labels)\n",
    "    \n",
    "    # Discriminator loss\n",
    "    disc_loss = adversarial_loss(real_or_fake, fake_labels)\n",
    "    \n",
    "    return recon_loss, kl_loss, gen_loss, disc_loss\n",
    "\n",
    "# Training loop\n",
    "n_epochs = opt.n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    total_recon_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    total_gen_loss = 0\n",
    "    total_disc_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        batch_size = data.size(0)\n",
    "        data = data.to('cpu')\n",
    "        \n",
    "        # Train generator (encoder + decoder)\n",
    "        gen_optimizer.zero_grad()\n",
    "        x_recon, real_or_fake, mu, logvar = ganae(data)\n",
    "        recon_loss, kl_loss, gen_loss, _ = compute_loss(x_recon, data, real_or_fake, mu, logvar)\n",
    "        \n",
    "        # Add L2 regularization\n",
    "        l2_penalty = ganae.compute_l2_penalty()\n",
    "        \n",
    "        # Total generator loss\n",
    "        g_loss = recon_loss + kl_loss + gen_loss + l2_penalty\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        gen_optimizer.step()\n",
    "        \n",
    "        # Train discriminator\n",
    "        disc_optimizer.zero_grad()\n",
    "        _, real_or_fake, _, _ = ganae(data)\n",
    "        _, _, _, disc_loss = compute_loss(x_recon, data, real_or_fake, mu, logvar)\n",
    "        disc_loss.backward()\n",
    "        disc_optimizer.step()\n",
    "        \n",
    "        # Record losses\n",
    "        total_recon_loss += recon_loss.item()\n",
    "        total_kl_loss += kl_loss.item()\n",
    "        total_gen_loss += gen_loss.item()\n",
    "        total_disc_loss += disc_loss.item()\n",
    "        \n",
    "    # Average losses\n",
    "    avg_recon_loss = total_recon_loss / len(train_loader.dataset)\n",
    "    avg_kl_loss = total_kl_loss / len(train_loader.dataset)\n",
    "    avg_gen_loss = total_gen_loss / len(train_loader.dataset)\n",
    "    avg_disc_loss = total_disc_loss / len(train_loader.dataset)\n",
    "    \n",
    "    print(f\"\"\"Epoch [{epoch+1}/{n_epochs}]\n",
    "    Reconstruction Loss: {avg_recon_loss:.4f}\n",
    "    KL Loss: {avg_kl_loss:.4f}\"\"\")\n",
    "    # print(f\"Generator Loss: {avg_gen_loss:.4f}\")\n",
    "    # print(f\"Discriminator Loss: {avg_disc_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE: 68.3799, MSE: 6.3320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68.37991318359374, 6.331951708984375)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate error\n",
    "def calculate_error(model, loader):\n",
    "    model.eval()\n",
    "    total_bce = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            data = data.view(data.size(0), -1)\n",
    "            recon_data, _ = model(data)\n",
    "            recon_data = recon_data.view(data.size(0), -1)\n",
    "            bce = F.binary_cross_entropy(recon_data, data, reduction='sum')\n",
    "            total_bce += bce.item()\n",
    "            mse = F.mse_loss(recon_data, data, reduction='sum')\n",
    "            total_mse += mse.item()\n",
    "            total_samples += data.size(0)\n",
    "\n",
    "    avg_bce = total_bce / total_samples\n",
    "    avg_mse = total_mse / total_samples\n",
    "    print(f\"BCE: {avg_bce:.4f}, MSE: {avg_mse:.4f}\")\n",
    "    return avg_bce, avg_mse\n",
    "\n",
    "calculate_error(ganae, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_gan_ae(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate classification error using the trained GAN-AE model and a logistic regression classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained GAN-AE model with an encoder.\n",
    "    - loader: DataLoader providing batches of (data, labels).\n",
    "\n",
    "    Returns:\n",
    "    - err: Classification error percentage.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    latents, labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in loader:\n",
    "            # Flatten data and move to the appropriate device\n",
    "            data = data.view(data.size(0), -1).to(next(model.parameters()).device)\n",
    "            label = label.to(next(model.parameters()).device)  # Ensure labels are also on the same device\n",
    "\n",
    "            if label is not None:  # Collect latent representations and labels\n",
    "                z = model.encoder(data)\n",
    "                latents.append(z.cpu().numpy())\n",
    "                labels.append(label.cpu().numpy())\n",
    "    \n",
    "    if not labels:  # Handle case where no labels are provided\n",
    "        print(\"No labels provided for classification.\")\n",
    "        return None\n",
    "\n",
    "    # Stack latents and labels into arrays\n",
    "    latents = np.vstack(latents)\n",
    "    labels = np.hstack(labels).reshape(-1)\n",
    "    print(f\"labels shape: {labels.shape}\")\n",
    "    print(f\"latents shape: {latents.shape}\")\n",
    "    # Ensure consistent lengths of latents and labels\n",
    "    min_len = min(len(latents), len(labels))\n",
    "    latents = latents[:min_len]\n",
    "    labels = labels[:min_len]\n",
    "\n",
    "    # Split latent data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(latents, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train logistic regression on training split\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test split\n",
    "    predictions = clf.predict(X_test)\n",
    "    err = 100 * (1 - accuracy_score(y_test, predictions))\n",
    "    print(f\"Classification Error: {err:.2f}%\")\n",
    "    \n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape: (100000,)\n",
      "latents shape: (10000, 20)\n",
      "Classification Error: 10.53%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.533333333333328"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_gan_ae(ganae,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_masked_mse(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate the Masked Mean Squared Error (M-MSE) for a given model on a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to evaluate.\n",
    "    - loader: DataLoader providing batches of test data.\n",
    "\n",
    "    Returns:\n",
    "    - avg_mse: The average masked MSE over the entire dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_mse = 0.0  # Accumulate total masked MSE\n",
    "    total_samples = 0  # Total number of samples processed\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "        for data, _ in loader:\n",
    "            # Flatten images into vectors (batch_size, D)\n",
    "            data = data.view(data.size(0), -1)  # Shape: (batch_size, D)\n",
    "\n",
    "            # Create a binary mask: Half of the columns are masked\n",
    "            mask = torch.ones_like(data, dtype=torch.bool)  # Shape: (batch_size, D)\n",
    "            mask[:, : data.size(1) // 2] = 0  # Mask the first half of the columns\n",
    "\n",
    "            # Apply the mask to the input data\n",
    "            masked_data = data * mask.float()  # Zero out the masked part\n",
    "            \n",
    "            # Forward pass through the model to get the reconstructed images\n",
    "            output = model(masked_data)  # Assumes model outputs reconstructed data\n",
    "            if isinstance(output, tuple):  # Extract reconstructed images if output is a tuple\n",
    "                reconstructed = output[0]\n",
    "            else:\n",
    "                reconstructed = output\n",
    "\n",
    "            # Ensure proper shape of reconstructed data\n",
    "            reconstructed = reconstructed.view(data.size(0), -1)  # Shape: (batch_size, D)\n",
    "\n",
    "            # Calculate the M-MSE for the current batch\n",
    "            mse_batch = masked_mse(data, reconstructed, mask)  # Masked MSE for this batch\n",
    "            \n",
    "            # Accumulate results\n",
    "            total_mse += mse_batch.item() * data.size(0)  # Multiply by batch size\n",
    "            total_samples += data.size(0)  # Update total sample count\n",
    "\n",
    "    # Compute the final average M-MSE across the dataset\n",
    "    avg_mse = total_mse / total_samples\n",
    "    print(f\"Average Masked MSE: {avg_mse:.4f}\")\n",
    "\n",
    "    return avg_mse\n",
    "\n",
    "\n",
    "# Helper function for batch-level Masked MSE\n",
    "def masked_mse(x, x_hat, mask):\n",
    "    \"\"\"\n",
    "    Compute the Masked Mean Squared Error (M-MSE) for a single batch.\n",
    "    \n",
    "    Parameters:\n",
    "    - x: Original images (batch_size, D), where D is the number of pixels in each image.\n",
    "    - x_hat: Reconstructed images (batch_size, D).\n",
    "    - mask: Binary mask (batch_size, D), where 1 indicates unmasked pixels and 0 indicates masked pixels.\n",
    "\n",
    "    Returns:\n",
    "    - m_mse: Masked mean squared error for the batch.\n",
    "    \"\"\"\n",
    "    # Compute squared error\n",
    "    error = (x - x_hat) ** 2\n",
    "    # Apply mask to focus only on masked-out regions\n",
    "    masked_error = error * (1 - mask.float())  \n",
    "\n",
    "    # Compute normalized MSE for the masked regions\n",
    "    batch_mse = masked_error.sum(dim=1) / (1 - mask.float()).sum(dim=1)\n",
    "\n",
    "    # Return average masked MSE for the batch\n",
    "    return batch_mse.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Masked MSE: 19.4237\n",
      "19.423651809692384\n"
     ]
    }
   ],
   "source": [
    "avg_mse = evaluate_masked_mse(ganae, test_loader)\n",
    "print(avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
