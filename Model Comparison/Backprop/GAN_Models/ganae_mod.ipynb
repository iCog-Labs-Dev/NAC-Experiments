{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the image shape  (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Adjust sys.argv to remove unwanted Jupyter arguments\n",
    "sys.argv = sys.argv[:1]  # Keep only the script name, remove Jupyter's arguments\n",
    "\n",
    "# Now proceed with argparse as usual\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=200, help=\"size of the batches\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of CPU threads for data loading\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=2000, help=\"interval between image sampling\")\n",
    "\n",
    "# Parse the arguments\n",
    "opt = parser.parse_args()\n",
    "\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "print(\"this is the image shape \", img_shape)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Loading Classes and Functions\n",
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, dataX, dataY=None):\n",
    "        self.dataX = np.load(dataX)\n",
    "        self.dataY = np.load(dataY) if dataY is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataX)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.dataX[idx], dtype=torch.float32)\n",
    "        label = (\n",
    "            torch.tensor(self.dataY[idx], dtype=torch.long)\n",
    "            if self.dataY is not None\n",
    "            else None\n",
    "        )\n",
    "        return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "dataX = \"../../../data/mnist/trainX.npy\"\n",
    "dataY = \"../../../data/mnist/trainY.npy\"\n",
    "devX = \"../../../data/mnist/validX.npy\"\n",
    "devY = \"../../../data/mnist/validY.npy\"\n",
    "testX = \"../../../data/mnist/testX.npy\"\n",
    "testY = \"../../../data/mnist/testY.npy\"\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset = NumpyDataset(dataX, dataY)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "dev_dataset = NumpyDataset(devX, devY)\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=200, shuffle=False)\n",
    "\n",
    "test_dataset = NumpyDataset(testX, testY)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=200, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.mu_layer = nn.Linear(hidden_dims[1], latent_dim)\n",
    "        self.logvar_layer = nn.Linear(hidden_dims[1], latent_dim)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in [*self.model, self.mu_layer, self.logvar_layer]:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        h = self.model(x)\n",
    "        mu = self.mu_layer(h)\n",
    "        logvar = self.logvar_layer(h)\n",
    "        return mu, logvar\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim, input_dim, hidden_dims):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[1], hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[0], input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, z):\n",
    "        x_recon = self.model(z)\n",
    "        return x_recon.view(-1, 1, 28, 28)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dims):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dims[1], 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in self.model:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "                nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z)\n",
    "\n",
    "def reparameterize(mu, logvar):\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    eps = torch.randn_like(std)\n",
    "    return mu + eps * std\n",
    "\n",
    "class GANAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dims, latent_dim, l2_lambda=1e-3):\n",
    "        super(GANAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dims, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, input_dim, hidden_dims)\n",
    "        self.discriminator = Discriminator(latent_dim, hidden_dims)\n",
    "        self.l2_lambda = l2_lambda\n",
    "\n",
    "    def compute_l2_penalty(self):\n",
    "        l2_penalty = 0\n",
    "        for param in self.decoder.parameters():\n",
    "            if param.requires_grad:\n",
    "                l2_penalty += torch.sum(param**2)\n",
    "        return self.l2_lambda * l2_penalty\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = reparameterize(mu, logvar)\n",
    "        x_recon = self.decoder(z)\n",
    "        real_or_fake = torch.sigmoid(self.discriminator(z))\n",
    "        return x_recon, real_or_fake, mu, logvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss Functions ---\n",
    "def bce_loss(pred, target):\n",
    "    return F.binary_cross_entropy(pred, target,reduction=\"sum\")\n",
    "\n",
    "def gan_ae_loss(recon_x, x, real_or_fake, real_label=1, fake_label=0):\n",
    "    # Reconstruction loss\n",
    "    recon_loss =bce_loss(recon_x, x)\n",
    "\n",
    "    # Discriminator loss (binary cross entropy)\n",
    "    d_loss_real = bce_loss(real_or_fake, torch.full_like(real_or_fake, real_label))\n",
    "    d_loss_fake = bce_loss(real_or_fake, torch.full_like(real_or_fake, fake_label))\n",
    "\n",
    "    return recon_loss + d_loss_real + d_loss_fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50]\n",
      "    Reconstruction Loss: 156.2635\n",
      "    KL Loss: 8.3078\n",
      "Epoch [2/50]\n",
      "    Reconstruction Loss: 109.5181\n",
      "    KL Loss: 13.0183\n",
      "Epoch [3/50]\n",
      "    Reconstruction Loss: 100.5738\n",
      "    KL Loss: 13.9653\n",
      "Epoch [4/50]\n",
      "    Reconstruction Loss: 96.4678\n",
      "    KL Loss: 14.4452\n",
      "Epoch [5/50]\n",
      "    Reconstruction Loss: 92.9108\n",
      "    KL Loss: 15.1979\n",
      "Epoch [6/50]\n",
      "    Reconstruction Loss: 89.4688\n",
      "    KL Loss: 15.9049\n",
      "Epoch [7/50]\n",
      "    Reconstruction Loss: 86.9907\n",
      "    KL Loss: 16.4014\n",
      "Epoch [8/50]\n",
      "    Reconstruction Loss: 84.7705\n",
      "    KL Loss: 16.8140\n",
      "Epoch [9/50]\n",
      "    Reconstruction Loss: 83.2108\n",
      "    KL Loss: 17.1745\n",
      "Epoch [10/50]\n",
      "    Reconstruction Loss: 81.9077\n",
      "    KL Loss: 17.4760\n",
      "Epoch [11/50]\n",
      "    Reconstruction Loss: 80.9458\n",
      "    KL Loss: 17.6600\n",
      "Epoch [12/50]\n",
      "    Reconstruction Loss: 79.9866\n",
      "    KL Loss: 17.8113\n",
      "Epoch [13/50]\n",
      "    Reconstruction Loss: 79.6533\n",
      "    KL Loss: 17.9222\n",
      "Epoch [14/50]\n",
      "    Reconstruction Loss: 79.0498\n",
      "    KL Loss: 18.0131\n",
      "Epoch [15/50]\n",
      "    Reconstruction Loss: 78.7225\n",
      "    KL Loss: 18.1089\n",
      "Epoch [16/50]\n",
      "    Reconstruction Loss: 78.4361\n",
      "    KL Loss: 18.1797\n",
      "Epoch [17/50]\n",
      "    Reconstruction Loss: 78.0813\n",
      "    KL Loss: 18.2346\n",
      "Epoch [18/50]\n",
      "    Reconstruction Loss: 77.6204\n",
      "    KL Loss: 18.3059\n",
      "Epoch [19/50]\n",
      "    Reconstruction Loss: 77.4507\n",
      "    KL Loss: 18.3124\n",
      "Epoch [20/50]\n",
      "    Reconstruction Loss: 77.1764\n",
      "    KL Loss: 18.3966\n",
      "Epoch [21/50]\n",
      "    Reconstruction Loss: 76.7663\n",
      "    KL Loss: 18.4451\n",
      "Epoch [22/50]\n",
      "    Reconstruction Loss: 76.7796\n",
      "    KL Loss: 18.4518\n",
      "Epoch [23/50]\n",
      "    Reconstruction Loss: 76.5710\n",
      "    KL Loss: 18.5052\n",
      "Epoch [24/50]\n",
      "    Reconstruction Loss: 76.4740\n",
      "    KL Loss: 18.5431\n",
      "Epoch [25/50]\n",
      "    Reconstruction Loss: 76.3985\n",
      "    KL Loss: 18.5615\n",
      "Epoch [26/50]\n",
      "    Reconstruction Loss: 76.0910\n",
      "    KL Loss: 18.5470\n",
      "Epoch [27/50]\n",
      "    Reconstruction Loss: 76.0833\n",
      "    KL Loss: 18.6186\n",
      "Epoch [28/50]\n",
      "    Reconstruction Loss: 75.9878\n",
      "    KL Loss: 18.6396\n",
      "Epoch [29/50]\n",
      "    Reconstruction Loss: 75.8347\n",
      "    KL Loss: 18.6396\n",
      "Epoch [30/50]\n",
      "    Reconstruction Loss: 75.6503\n",
      "    KL Loss: 18.6723\n",
      "Epoch [31/50]\n",
      "    Reconstruction Loss: 75.5527\n",
      "    KL Loss: 18.6946\n",
      "Epoch [32/50]\n",
      "    Reconstruction Loss: 75.3386\n",
      "    KL Loss: 18.6946\n",
      "Epoch [33/50]\n",
      "    Reconstruction Loss: 75.2674\n",
      "    KL Loss: 18.7215\n",
      "Epoch [34/50]\n",
      "    Reconstruction Loss: 75.2006\n",
      "    KL Loss: 18.7405\n",
      "Epoch [35/50]\n",
      "    Reconstruction Loss: 74.9674\n",
      "    KL Loss: 18.7525\n",
      "Epoch [36/50]\n",
      "    Reconstruction Loss: 75.1864\n",
      "    KL Loss: 18.7922\n",
      "Epoch [37/50]\n",
      "    Reconstruction Loss: 74.8049\n",
      "    KL Loss: 18.7713\n",
      "Epoch [38/50]\n",
      "    Reconstruction Loss: 74.9365\n",
      "    KL Loss: 18.7972\n",
      "Epoch [39/50]\n",
      "    Reconstruction Loss: 74.9164\n",
      "    KL Loss: 18.8113\n",
      "Epoch [40/50]\n",
      "    Reconstruction Loss: 74.8896\n",
      "    KL Loss: 18.7952\n",
      "Epoch [41/50]\n",
      "    Reconstruction Loss: 74.6331\n",
      "    KL Loss: 18.8555\n",
      "Epoch [42/50]\n",
      "    Reconstruction Loss: 74.5899\n",
      "    KL Loss: 18.9037\n",
      "Epoch [43/50]\n",
      "    Reconstruction Loss: 74.4329\n",
      "    KL Loss: 18.8632\n",
      "Epoch [44/50]\n",
      "    Reconstruction Loss: 74.5001\n",
      "    KL Loss: 18.8686\n",
      "Epoch [45/50]\n",
      "    Reconstruction Loss: 74.1713\n",
      "    KL Loss: 18.8934\n",
      "Epoch [46/50]\n",
      "    Reconstruction Loss: 74.0973\n",
      "    KL Loss: 18.9302\n",
      "Epoch [47/50]\n",
      "    Reconstruction Loss: 74.1366\n",
      "    KL Loss: 18.9126\n",
      "Epoch [48/50]\n",
      "    Reconstruction Loss: 73.9650\n",
      "    KL Loss: 18.9365\n",
      "Epoch [49/50]\n",
      "    Reconstruction Loss: 74.2048\n",
      "    KL Loss: 18.9231\n",
      "Epoch [50/50]\n",
      "    Reconstruction Loss: 74.3078\n",
      "    KL Loss: 18.9144\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "\n",
    "# Initialize model with proper parameters\n",
    "input_dim = 784  # 28x28 for MNIST\n",
    "hidden_dims = [360, 360]  # Example dimensions\n",
    "latent_dim = 20  # Example latent dimension\n",
    "ganae = GANAE(input_dim=input_dim, hidden_dims=hidden_dims, latent_dim=latent_dim)\n",
    "\n",
    "# Separate optimizers for generator (encoder+decoder) and discriminator\n",
    "gen_optimizer = torch.optim.Adam(list(ganae.encoder.parameters()) + \n",
    "                               list(ganae.decoder.parameters()), lr=0.006)\n",
    "disc_optimizer = torch.optim.Adam(ganae.discriminator.parameters(), lr=0.05)\n",
    "\n",
    "# Loss functions\n",
    "reconstruction_loss = nn.BCELoss(reduction='sum')\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "\n",
    "def rescale_gradients(model, max_norm=5.0):\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
    "\n",
    "\n",
    "\n",
    "def compute_loss(x_recon, x, real_or_fake, mu, logvar):\n",
    "    # Flatten the input and reconstruction for BCE loss\n",
    "    x_recon_flat = x_recon.view(-1, input_dim)\n",
    "    x_flat = x.view(-1, input_dim)\n",
    "    \n",
    "    # Reconstruction loss\n",
    "    recon_loss = reconstruction_loss(x_recon_flat, x_flat)\n",
    "    \n",
    "    # KL divergence\n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    \n",
    "    # Adversarial loss\n",
    "    real_labels = torch.ones(real_or_fake.size()).to(x.device)\n",
    "    fake_labels = torch.zeros(real_or_fake.size()).to(x.device)\n",
    "    \n",
    "    # Generator tries to fool discriminator\n",
    "    gen_loss = adversarial_loss(real_or_fake, real_labels)\n",
    "    \n",
    "    # Discriminator loss\n",
    "    disc_loss = adversarial_loss(real_or_fake, fake_labels)\n",
    "    \n",
    "    return recon_loss, kl_loss, gen_loss, disc_loss\n",
    "\n",
    "# Training loop\n",
    "n_epochs = opt.n_epochs\n",
    "for epoch in range(n_epochs):\n",
    "    total_recon_loss = 0\n",
    "    total_kl_loss = 0\n",
    "    total_gen_loss = 0\n",
    "    total_disc_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        batch_size = data.size(0)\n",
    "        data = data.to('cpu')\n",
    "        data = (data > 0.5).float()\n",
    "        \n",
    "        # Train generator (encoder + decoder)\n",
    "        gen_optimizer.zero_grad()\n",
    "        x_recon, real_or_fake, mu, logvar = ganae(data)\n",
    "        recon_loss, kl_loss, gen_loss, _ = compute_loss(x_recon, data, real_or_fake, mu, logvar)\n",
    "        \n",
    "        # Add L2 regularization\n",
    "        l2_penalty = ganae.compute_l2_penalty()\n",
    "        \n",
    "        # Total generator loss\n",
    "        g_loss = recon_loss + kl_loss + gen_loss + l2_penalty\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        rescale_gradients(ganae)\n",
    "        gen_optimizer.step()\n",
    "        \n",
    "        # Train discriminator\n",
    "        disc_optimizer.zero_grad()\n",
    "        _, real_or_fake, _, _ = ganae(data)\n",
    "        _, _, _, disc_loss = compute_loss(x_recon, data, real_or_fake, mu, logvar)\n",
    "        disc_loss.backward()\n",
    "        rescale_gradients(ganae)\n",
    "        disc_optimizer.step()\n",
    "        \n",
    "        # Record losses\n",
    "        total_recon_loss += recon_loss.item()\n",
    "        total_kl_loss += kl_loss.item()\n",
    "        total_gen_loss += gen_loss.item()\n",
    "        total_disc_loss += disc_loss.item()\n",
    "        \n",
    "    # Average losses\n",
    "    avg_recon_loss = total_recon_loss / len(train_loader.dataset)\n",
    "    avg_kl_loss = total_kl_loss / len(train_loader.dataset)\n",
    "    avg_gen_loss = total_gen_loss / len(train_loader.dataset)\n",
    "    avg_disc_loss = total_disc_loss / len(train_loader.dataset)\n",
    "    \n",
    "    print(f\"\"\"Epoch [{epoch+1}/{n_epochs}]\n",
    "    Reconstruction Loss: {avg_recon_loss:.4f}\n",
    "    KL Loss: {avg_kl_loss:.4f}\"\"\")\n",
    "    # print(f\"Generator Loss: {avg_gen_loss:.4f}\")\n",
    "    # print(f\"Discriminator Loss: {avg_disc_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5867/2405283806.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mavg_bce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_mse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mcalculate_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mganae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5867/2405283806.py\u001b[0m in \u001b[0;36mcalculate_error\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mrecon_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mrecon_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecon_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mbce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "# Calculate error\n",
    "def calculate_error(model, loader):\n",
    "    model.eval()\n",
    "    total_bce = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            data = data.view(data.size(0), -1)\n",
    "            recon_data, _ = model(data)\n",
    "            recon_data = recon_data.view(data.size(0), -1)\n",
    "            bce = F.binary_cross_entropy(recon_data, data, reduction='sum')\n",
    "            total_bce += bce.item()\n",
    "            mse = F.mse_loss(recon_data, data, reduction='sum')\n",
    "            total_mse += mse.item()\n",
    "            total_samples += data.size(0)\n",
    "\n",
    "    avg_bce = total_bce / total_samples\n",
    "    avg_mse = total_mse / total_samples\n",
    "    print(f\"BCE: {avg_bce:.4f}, MSE: {avg_mse:.4f}\")\n",
    "    return avg_bce, avg_mse\n",
    "\n",
    "calculate_error(ganae, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_classification_gan_ae(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate classification error using the trained GAN-AE model and a logistic regression classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained GAN-AE model with an encoder.\n",
    "    - loader: DataLoader providing batches of (data, labels).\n",
    "\n",
    "    Returns:\n",
    "    - err: Classification error percentage.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    latents, labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in loader:\n",
    "            # Flatten data and move to the appropriate device\n",
    "            data = data.view(data.size(0), -1).to(next(model.parameters()).device)\n",
    "            label = label.to(next(model.parameters()).device)\n",
    "            \n",
    "            if label is not None:\n",
    "                mu, logvar = model.encoder(data)\n",
    "                z = reparameterize(mu, logvar)\n",
    "                latents.append(z.cpu().numpy())\n",
    "                labels.append(label.cpu().numpy())\n",
    "    \n",
    "    if not labels:\n",
    "        print(\"No labels provided for classification.\")\n",
    "        return None\n",
    "\n",
    "    # Stack latents and labels into arrays\n",
    "    latents = np.vstack(latents)\n",
    "    labels = np.hstack(labels).reshape(-1)\n",
    "    print(f\"labels shape: {labels.shape}\")\n",
    "    print(f\"latents shape: {latents.shape}\")\n",
    "    \n",
    "    # Ensure consistent lengths of latents and labels\n",
    "    min_len = min(len(latents), len(labels))\n",
    "    latents = latents[:min_len]\n",
    "    labels = labels[:min_len]\n",
    "\n",
    "    # Split latent data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(latents, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train logistic regression on training split\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test split\n",
    "    predictions = clf.predict(X_test)\n",
    "    err = 100 * (1 - accuracy_score(y_test, predictions))\n",
    "    print(f\"Classification Error: {err:.2f}%\")\n",
    "    \n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape: (100000,)\n",
      "latents shape: (10000, 20)\n",
      "Classification Error: 10.53%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.533333333333328"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_gan_ae(ganae,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_masked_mse(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate the Masked Mean Squared Error (M-MSE) for a given model on a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to evaluate.\n",
    "    - loader: DataLoader providing batches of test data.\n",
    "\n",
    "    Returns:\n",
    "    - avg_mse: The average masked MSE over the entire dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_mse = 0.0  # Accumulate total masked MSE\n",
    "    total_samples = 0  # Total number of samples processed\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "        for data, _ in loader:\n",
    "            # Flatten images into vectors (batch_size, D)\n",
    "            data = data.view(data.size(0), -1)  # Shape: (batch_size, D)\n",
    "\n",
    "            # Create a binary mask: Half of the columns are masked\n",
    "            mask = torch.ones_like(data, dtype=torch.bool)  # Shape: (batch_size, D)\n",
    "            mask[:, : data.size(1) // 2] = 0  # Mask the first half of the columns\n",
    "\n",
    "\n",
    "            masked_data = data * mask.float()  # Zero out the masked part\n",
    "            \n",
    "            output = model(masked_data)  # Assumes model outputs reconstructed data\n",
    "            if isinstance(output, tuple):  # Extract reconstructed images if output is a tuple\n",
    "                reconstructed = output[0]\n",
    "            else:\n",
    "                reconstructed = output\n",
    "            reconstructed = reconstructed.view(data.size(0), -1)  # Shape: (batch_size, D)\n",
    "\n",
    "            mse_batch = masked_mse(data, reconstructed, mask)  # Masked MSE for this batch\n",
    "            \n",
    "            # Accumulate results\n",
    "            total_mse += mse_batch.item() * data.size(0)  # Multiply by batch size\n",
    "            total_samples += data.size(0)  # Update total sample count\n",
    "\n",
    "    # Compute the final average M-MSE across the dataset\n",
    "    avg_mse = total_mse / total_samples\n",
    "    print(f\"Average Masked MSE: {avg_mse:.4f}\")\n",
    "\n",
    "    return avg_mse\n",
    "\n",
    "\n",
    "# Helper function for batch-level Masked MSE\n",
    "def masked_mse(x, x_hat, mask):\n",
    "    \"\"\"\n",
    "    Compute the Masked Mean Squared Error (M-MSE) for a single batch.\n",
    "    \n",
    "    Parameters:\n",
    "    - x: Original images (batch_size, D), where D is the number of pixels in each image.\n",
    "    - x_hat: Reconstructed images (batch_size, D).\n",
    "    - mask: Binary mask (batch_size, D), where 1 indicates unmasked pixels and 0 indicates masked pixels.\n",
    "\n",
    "    Returns:\n",
    "    - m_mse: Masked mean squared error for the batch.\n",
    "    \"\"\"\n",
    "    # Compute squared error\n",
    "    error = (x - x_hat) ** 2\n",
    "    # Apply mask to focus only on masked-out regions\n",
    "    masked_error = error * (1 - mask.float())  \n",
    "\n",
    "    # Compute normalized MSE for the masked regions\n",
    "    batch_mse = masked_error.sum(dim=1) / (1 - mask.float()).sum(dim=1)\n",
    "\n",
    "    # Return average masked MSE for the batch\n",
    "    return batch_mse.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Masked MSE: 13.4537\n",
      "13.453733501434327\n"
     ]
    }
   ],
   "source": [
    "avg_mse = evaluate_masked_mse(ganae, test_loader)\n",
    "print(avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting latent vectors from dataLoader using the provided model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5867/2863695804.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mevaluate_density_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mganae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5867/2863695804.py\u001b[0m in \u001b[0;36mevaluate_density_model\u001b[0;34m(model, train_loader, test_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_logpx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate_logpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_density_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_gmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlog_px\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_logpx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Zeamani/icoglabs/experimental/NAC-Experiments/Model Comparison/density/fit_gmm.py\u001b[0m in \u001b[0;36mfit_gmm\u001b[0;34m(data_loader, model, latent_dim, gmm_file, n_components, max_iter, assume_diag_cov, init_kmeans, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Check if the output is a tuple, and extract the tensor if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0mlatent_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlatent_vectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Extract the first element\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got tuple"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add the parent directory of GAN_Models to sys.path\n",
    "sys.path.append(os.path.abspath(\"../../\"))  # Adjust the path as necessary\n",
    "\n",
    "from density.fit_gmm import fit_gmm\n",
    "from density.eval_logpx import evaluate_logpx\n",
    "def evaluate_density_model(model,train_loader, test_loader):\n",
    "    gmm = fit_gmm(model=model,data_loader=train_loader,latent_dim=20)\n",
    "\n",
    "    log_px = evaluate_logpx(model=model,gmm=gmm,data_loader=test_loader,latent_dim=20)\n",
    "\n",
    "    print(f\"Log-likelihood: {log_px:.4f}\")\n",
    "    return log_px\n",
    "\n",
    "\n",
    "evaluate_density_model(model=ganae,train_loader=train_loader,test_loader=test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting latent vectors from dataLoader using the provided model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5867/4171663602.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_density_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mganae\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5867/2863695804.py\u001b[0m in \u001b[0;36mevaluate_density_model\u001b[0;34m(model, train_loader, test_loader)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdensity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_logpx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate_logpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_density_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgmm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_gmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlog_px\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_logpx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgmm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Zeamani/icoglabs/experimental/NAC-Experiments/Model Comparison/density/fit_gmm.py\u001b[0m in \u001b[0;36mfit_gmm\u001b[0;34m(data_loader, model, latent_dim, gmm_file, n_components, max_iter, assume_diag_cov, init_kmeans, device)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mdata_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Expected latent dimension {latent_dim}, but got {data.size(1)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got tuple"
     ]
    }
   ],
   "source": [
    "evaluate_density_model(model=ganae,train_loader=train_loader,test_loader=test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
