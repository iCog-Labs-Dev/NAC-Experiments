{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is the image shape  (1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Adjust sys.argv to remove unwanted Jupyter arguments\n",
    "sys.argv = sys.argv[:1]  # Keep only the script name, remove Jupyter's arguments\n",
    "\n",
    "# Now proceed with argparse as usual\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=50, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=200, help=\"size of the batches\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of CPU threads for data loading\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=28, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "parser.add_argument(\"--sample_interval\", type=int, default=2000, help=\"interval between image sampling\")\n",
    "\n",
    "# Parse the arguments\n",
    "opt = parser.parse_args()\n",
    "\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "print(\"this is the image shape \", img_shape)\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if cuda:\n",
    "    torch.cuda.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data Loading Classes and Functions\n",
    "class NumpyDataset(Dataset):\n",
    "    def __init__(self, dataX, dataY=None):\n",
    "        self.dataX = np.load(dataX)\n",
    "        self.dataY = np.load(dataY) if dataY is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataX)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = torch.tensor(self.dataX[idx], dtype=torch.float32)\n",
    "        label = (\n",
    "            torch.tensor(self.dataY[idx], dtype=torch.long)\n",
    "            if self.dataY is not None\n",
    "            else None\n",
    "        )\n",
    "        return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "dataX = \"../../../data/mnist/trainX.npy\"\n",
    "dataY = \"../../../data/mnist/trainY.npy\"\n",
    "devX = \"../../../data/mnist/validX.npy\"\n",
    "devY = \"../../../data/mnist/validY.npy\"\n",
    "testX = \"../../../data/mnist/testX.npy\"\n",
    "testY = \"../../../data/mnist/testY.npy\"\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset = NumpyDataset(dataX, dataY)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=200, shuffle=True)\n",
    "\n",
    "dev_dataset = NumpyDataset(devX, devY)\n",
    "dev_loader = DataLoader(dataset=dev_dataset, batch_size=200, shuffle=False)\n",
    "\n",
    "test_dataset = NumpyDataset(testX, testY)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=200, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Encoder (Same as VAE) ---\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=360, latent_dim=20):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, latent_dim)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in [self.fc1, self.fc2, self.fc3]:\n",
    "            nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        z = self.fc3(x)  # Latent space representation\n",
    "        return z\n",
    "\n",
    "\n",
    "# --- Decoder (Generator) ---\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=20, hidden_dim=360, output_dim=784):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(latent_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in [self.fc1, self.fc2, self.fc3]:\n",
    "            nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        z = torch.sigmoid(self.fc3(z))  # Sigmoid activation in the output layer\n",
    "        return z\n",
    "\n",
    "\n",
    "# --- Discriminator (GAN) ---\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=360):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 1)  # Output a single value for real/fake classification\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self, sigma=0.05):\n",
    "        for layer in [self.fc1, self.fc2, self.fc3]:\n",
    "            nn.init.normal_(layer.weight, mean=0.0, std=sigma)\n",
    "            nn.init.constant_(layer.bias, 0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))  # Sigmoid activation for binary output (real/fake)\n",
    "        return x\n",
    "\n",
    "\n",
    "# --- GAN-AE Model ---\n",
    "class GANAE(nn.Module):\n",
    "    def __init__(self, input_dim=784, hidden_dim=360, latent_dim=20):\n",
    "        super(GANAE, self).__init__()\n",
    "        self.encoder = Encoder(input_dim, hidden_dim, latent_dim)\n",
    "        self.decoder = Decoder(latent_dim, hidden_dim, input_dim)\n",
    "        self.discriminator = Discriminator(input_dim, hidden_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        real_or_fake = self.discriminator(x_recon)\n",
    "        return x_recon, real_or_fake\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Loss Functions ---\n",
    "def bce_loss(pred, target):\n",
    "    return F.binary_cross_entropy(pred, target,reduction=\"sum\")\n",
    "\n",
    "def gan_ae_loss(recon_x, x, real_or_fake, real_label=1, fake_label=0):\n",
    "    # Reconstruction loss\n",
    "    recon_loss =bce_loss(recon_x, x)\n",
    "\n",
    "    # Discriminator loss (binary cross entropy)\n",
    "    d_loss_real = bce_loss(real_or_fake, torch.full_like(real_or_fake, real_label))\n",
    "    d_loss_fake = bce_loss(real_or_fake, torch.full_like(real_or_fake, fake_label))\n",
    "\n",
    "    return recon_loss + d_loss_real + d_loss_fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 234.2925\n",
      "Epoch 2, Loss: 137.9755\n",
      "Epoch 3, Loss: 113.5640\n",
      "Epoch 4, Loss: 101.9898\n",
      "Epoch 5, Loss: 96.4930\n",
      "Epoch 6, Loss: 92.3891\n",
      "Epoch 7, Loss: 88.9045\n",
      "Epoch 8, Loss: 86.3177\n",
      "Epoch 9, Loss: 84.3004\n",
      "Epoch 10, Loss: 82.5445\n",
      "Epoch 11, Loss: 81.1324\n",
      "Epoch 12, Loss: 80.0676\n",
      "Epoch 13, Loss: 79.2167\n",
      "Epoch 14, Loss: 78.4626\n",
      "Epoch 15, Loss: 77.7974\n",
      "Epoch 16, Loss: 77.2049\n",
      "Epoch 17, Loss: 76.6436\n",
      "Epoch 18, Loss: 76.1616\n",
      "Epoch 19, Loss: 75.7200\n",
      "Epoch 20, Loss: 75.2922\n",
      "Epoch 21, Loss: 74.9039\n",
      "Epoch 22, Loss: 74.5392\n",
      "Epoch 23, Loss: 74.2301\n",
      "Epoch 24, Loss: 73.9024\n",
      "Epoch 25, Loss: 73.6023\n",
      "Epoch 26, Loss: 73.3210\n",
      "Epoch 27, Loss: 73.0784\n",
      "Epoch 28, Loss: 72.8321\n",
      "Epoch 29, Loss: 72.6034\n",
      "Epoch 30, Loss: 72.3800\n",
      "Epoch 31, Loss: 72.1748\n",
      "Epoch 32, Loss: 71.9646\n",
      "Epoch 33, Loss: 71.7872\n",
      "Epoch 34, Loss: 71.6073\n",
      "Epoch 35, Loss: 71.4411\n",
      "Epoch 36, Loss: 71.2781\n",
      "Epoch 37, Loss: 71.1312\n",
      "Epoch 38, Loss: 70.9605\n",
      "Epoch 39, Loss: 70.8261\n",
      "Epoch 40, Loss: 70.6874\n",
      "Epoch 41, Loss: 70.5599\n",
      "Epoch 42, Loss: 70.4220\n",
      "Epoch 43, Loss: 70.3028\n",
      "Epoch 44, Loss: 70.1748\n",
      "Epoch 45, Loss: 70.0547\n",
      "Epoch 46, Loss: 69.9413\n",
      "Epoch 47, Loss: 69.8373\n",
      "Epoch 48, Loss: 69.7262\n",
      "Epoch 49, Loss: 69.6320\n",
      "Epoch 50, Loss: 69.5172\n"
     ]
    }
   ],
   "source": [
    "# --- Training Loop ---\n",
    "ganae = GANAE(input_dim=784)\n",
    "optimizer = torch.optim.Adam(ganae.parameters(), lr=0.0002)\n",
    "\n",
    "for epoch in range(opt.n_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, (data, _) in enumerate(train_loader):\n",
    "        data = data.view(data.size(0), -1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        recon_data, real_or_fake = ganae(data)\n",
    "        loss = gan_ae_loss(recon_data, data, real_or_fake)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() # * data.size(0)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader.dataset):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCE: 68.3799, MSE: 6.3320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(68.37991318359374, 6.331951708984375)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate error\n",
    "def calculate_error(model, loader):\n",
    "    model.eval()\n",
    "    total_bce = 0.0\n",
    "    total_mse = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in loader:\n",
    "            data = data.view(data.size(0), -1)\n",
    "            recon_data, _ = model(data)\n",
    "            recon_data = recon_data.view(data.size(0), -1)\n",
    "            bce = F.binary_cross_entropy(recon_data, data, reduction='sum')\n",
    "            total_bce += bce.item()\n",
    "            mse = F.mse_loss(recon_data, data, reduction='sum')\n",
    "            total_mse += mse.item()\n",
    "            total_samples += data.size(0)\n",
    "\n",
    "    avg_bce = total_bce / total_samples\n",
    "    avg_mse = total_mse / total_samples\n",
    "    print(f\"BCE: {avg_bce:.4f}, MSE: {avg_mse:.4f}\")\n",
    "    return avg_bce, avg_mse\n",
    "\n",
    "calculate_error(ganae, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_gan_ae(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate classification error using the trained GAN-AE model and a logistic regression classifier.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained GAN-AE model with an encoder.\n",
    "    - loader: DataLoader providing batches of (data, labels).\n",
    "\n",
    "    Returns:\n",
    "    - err: Classification error percentage.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    latents, labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, label in loader:\n",
    "            # Flatten data and move to the appropriate device\n",
    "            data = data.view(data.size(0), -1).to(next(model.parameters()).device)\n",
    "            label = label.to(next(model.parameters()).device)  # Ensure labels are also on the same device\n",
    "\n",
    "            if label is not None:  # Collect latent representations and labels\n",
    "                z = model.encoder(data)\n",
    "                latents.append(z.cpu().numpy())\n",
    "                labels.append(label.cpu().numpy())\n",
    "    \n",
    "    if not labels:  # Handle case where no labels are provided\n",
    "        print(\"No labels provided for classification.\")\n",
    "        return None\n",
    "\n",
    "    # Stack latents and labels into arrays\n",
    "    latents = np.vstack(latents)\n",
    "    labels = np.hstack(labels).reshape(-1)\n",
    "    print(f\"labels shape: {labels.shape}\")\n",
    "    print(f\"latents shape: {latents.shape}\")\n",
    "    # Ensure consistent lengths of latents and labels\n",
    "    min_len = min(len(latents), len(labels))\n",
    "    latents = latents[:min_len]\n",
    "    labels = labels[:min_len]\n",
    "\n",
    "    # Split latent data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(latents, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Train logistic regression on training split\n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate on test split\n",
    "    predictions = clf.predict(X_test)\n",
    "    err = 100 * (1 - accuracy_score(y_test, predictions))\n",
    "    print(f\"Classification Error: {err:.2f}%\")\n",
    "    \n",
    "    return err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels shape: (100000,)\n",
      "latents shape: (10000, 20)\n",
      "Classification Error: 10.53%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.533333333333328"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_gan_ae(ganae,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_masked_mse(model, loader):\n",
    "    \"\"\"\n",
    "    Evaluate the Masked Mean Squared Error (M-MSE) for a given model on a dataset.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained model to evaluate.\n",
    "    - loader: DataLoader providing batches of test data.\n",
    "\n",
    "    Returns:\n",
    "    - avg_mse: The average masked MSE over the entire dataset.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_mse = 0.0  # Accumulate total masked MSE\n",
    "    total_samples = 0  # Total number of samples processed\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
    "        for data, _ in loader:\n",
    "            # Flatten images into vectors (batch_size, D)\n",
    "            data = data.view(data.size(0), -1)  # Shape: (batch_size, D)\n",
    "\n",
    "            # Create a binary mask: Half of the columns are masked\n",
    "            mask = torch.ones_like(data, dtype=torch.bool)  # Shape: (batch_size, D)\n",
    "            mask[:, : data.size(1) // 2] = 0  # Mask the first half of the columns\n",
    "\n",
    "            # Apply the mask to the input data\n",
    "            masked_data = data * mask.float()  # Zero out the masked part\n",
    "            \n",
    "            # Forward pass through the model to get the reconstructed images\n",
    "            output = model(masked_data)  # Assumes model outputs reconstructed data\n",
    "            if isinstance(output, tuple):  # Extract reconstructed images if output is a tuple\n",
    "                reconstructed = output[0]\n",
    "            else:\n",
    "                reconstructed = output\n",
    "\n",
    "            # Ensure proper shape of reconstructed data\n",
    "            reconstructed = reconstructed.view(data.size(0), -1)  # Shape: (batch_size, D)\n",
    "\n",
    "            # Calculate the M-MSE for the current batch\n",
    "            mse_batch = masked_mse(data, reconstructed, mask)  # Masked MSE for this batch\n",
    "            \n",
    "            # Accumulate results\n",
    "            total_mse += mse_batch.item() * data.size(0)  # Multiply by batch size\n",
    "            total_samples += data.size(0)  # Update total sample count\n",
    "\n",
    "    # Compute the final average M-MSE across the dataset\n",
    "    avg_mse = total_mse / total_samples\n",
    "    print(f\"Average Masked MSE: {avg_mse:.4f}\")\n",
    "\n",
    "    return avg_mse\n",
    "\n",
    "\n",
    "# Helper function for batch-level Masked MSE\n",
    "def masked_mse(x, x_hat, mask):\n",
    "    \"\"\"\n",
    "    Compute the Masked Mean Squared Error (M-MSE) for a single batch.\n",
    "    \n",
    "    Parameters:\n",
    "    - x: Original images (batch_size, D), where D is the number of pixels in each image.\n",
    "    - x_hat: Reconstructed images (batch_size, D).\n",
    "    - mask: Binary mask (batch_size, D), where 1 indicates unmasked pixels and 0 indicates masked pixels.\n",
    "\n",
    "    Returns:\n",
    "    - m_mse: Masked mean squared error for the batch.\n",
    "    \"\"\"\n",
    "    # Compute squared error\n",
    "    error = (x - x_hat) ** 2\n",
    "    # Apply mask to focus only on masked-out regions\n",
    "    masked_error = error * (1 - mask.float())  \n",
    "\n",
    "    # Compute normalized MSE for the masked regions\n",
    "    batch_mse = masked_error.sum(dim=1) / (1 - mask.float()).sum(dim=1)\n",
    "\n",
    "    # Return average masked MSE for the batch\n",
    "    return batch_mse.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Masked MSE: 19.4237\n",
      "19.423651809692384\n"
     ]
    }
   ],
   "source": [
    "avg_mse = evaluate_masked_mse(ganae, test_loader)\n",
    "print(avg_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
